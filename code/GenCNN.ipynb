{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a neural network implement ver of deterministic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# min(a, b) = a - relu(a - b)\n",
    "# min(a+1,b)= b - relu(b - a - 1)\n",
    "\n",
    "#实际上， 只需要5,5，relu，5,3，relu，3,2，relu，2,1 几层即可。\n",
    "#这个求最小值是针对非负数的。\n",
    "\n",
    "#参数的trick全在这些数字中，它们构造了最短路算法。\n",
    "class Kernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "\n",
    "        #似乎用矩阵结合律还可以压层，不过为了可解释性就不压了。\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential()\n",
    "        self.linear_relu_stack.append(nn.Linear(5, 5, bias=False))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[1,0, 0, 0, 0],[1, -1, 0, 0, 0],[0, 0, 1, 0, 0],[0, 0, 1, -1, 0],[0, 0, 0, 0, 1]], dtype=torch.float32)\n",
    "        self.linear_relu_stack.append(nn.ReLU())\n",
    "        self.linear_relu_stack.append(nn.Linear(5, 3, bias=False))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[1,-1,0,0,0],[0,0,1,-1,0],[0,0,0,0,1]], dtype=torch.float32)\n",
    "        # self.linear_relu_stack.append(nn.ReLU())\n",
    "        self.linear_relu_stack.append(nn.Linear(3, 3, bias=False))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[1,0, 0],[1, -1, 0],[0, 0, 1]], dtype=torch.float32)\n",
    "        self.linear_relu_stack.append(nn.ReLU())\n",
    "        self.linear_relu_stack.append(nn.Linear(3, 2, bias=False))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[1,-1,0],[0,0,1]], dtype=torch.float32)\n",
    "        # self.linear_relu_stack.append(nn.ReLU())\n",
    "        self.linear_relu_stack.append(nn.Linear(2, 2))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[0,1],[-1, 1]], dtype=torch.float32)\n",
    "        self.linear_relu_stack[-1].bias.data = torch.tensor([0,-1], dtype=torch.float32)\n",
    "        self.linear_relu_stack.append(nn.ReLU())\n",
    "        self.linear_relu_stack.append(nn.Linear(2, 1, bias=False))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[1,-1]], dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        ret = self.linear_relu_stack(x)\n",
    "        return ret\n",
    "\n",
    "\n",
    "# model = Kernel().to(device)\n",
    "# print(model)\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, globalparam):\n",
    "        super().__init__()\n",
    "        self.globalparam = globalparam\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (1, 1, 1, 1), mode='constant', value=10000)\n",
    "        ret = torch.zeros(28, 28, dtype=torch.float32)\n",
    "        for i in range(1, 29):\n",
    "            for j in range(1, 29):\n",
    "                ret[i-1,j-1] = self.globalparam['kernel'](torch.tensor([[x[i-1,j], x[i,j-1], x[i+1,j], x[i,j+1], x[i,j]]], dtype=torch.float32))\n",
    "        ret = ret.detach() * self.globalparam['a'] + (1 - self.globalparam['input']) * self.globalparam['b']\n",
    "        ret = 10000 - nn.ReLU()(10000-ret)\n",
    "        return ret\n",
    "\n",
    "class Initializer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return random select a 1 in matrix x and make it 0, other are 10000\n",
    "        ret = torch.empty(x.shape).fill_(10000)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                if x[i,j] == 1:\n",
    "                    ret[i,j] = 0\n",
    "                    return ret\n",
    "        raise Exception(\"No 1 in x\")\n",
    "\n",
    "class CloseToMinus1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential()\n",
    "        self.linear_relu_stack.append(nn.Linear(1, 2))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[1], [-1]], dtype=torch.float32)\n",
    "        self.linear_relu_stack[-1].bias.data = torch.tensor([0.5, -1.5], dtype=torch.float32)\n",
    "        self.linear_relu_stack.append(nn.ReLU())\n",
    "        self.linear_relu_stack.append(nn.Linear(2, 1))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[-10,-10]], dtype=torch.float32)\n",
    "        self.linear_relu_stack[-1].bias.data = torch.tensor([1], dtype=torch.float32)\n",
    "        self.linear_relu_stack.append(nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        l = torch.tensor([[self.linear_relu_stack(torch.tensor([[i]], dtype=torch.float32)) for i in x]], dtype=torch.float32)\n",
    "        # x.apply_(self.linear_relu_stack)\n",
    "        return l\n",
    "\n",
    "class ExtractNet(nn.Module):\n",
    "    def __init__(self, globalparam):\n",
    "        super().__init__()\n",
    "        self.globalparam = globalparam\n",
    "        self.linear_relu_stack = nn.Sequential()\n",
    "        self.linear_relu_stack.append(nn.Linear(5, 4, bias=False))\n",
    "        self.linear_relu_stack[-1].weight.data = torch.tensor([[1, 0, 0, 0, -1],[0, 1, 0, 0, -1],[0, 0, 1, 0, -1],[0, 0, 0, 1, -1]], dtype=torch.float32)\n",
    "        \n",
    "        self.linear_relu_stack2 = nn.Sequential()\n",
    "        self.linear_relu_stack2.append(nn.Linear(4, 1))\n",
    "        self.linear_relu_stack2[-1].weight.data = torch.tensor([[1,1,1,1]], dtype=torch.float32)\n",
    "        self.linear_relu_stack2[-1].bias.data = torch.tensor([-1.5], dtype=torch.float32)\n",
    "        self.linear_relu_stack2.append(nn.ReLU())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        x = F.pad(x, (1, 1, 1, 1), mode='constant', value=10000)\n",
    "        ret = torch.zeros(28, 28, dtype=torch.float32)\n",
    "        for i in range(1, 29):\n",
    "            for j in range(1, 29):\n",
    "                tmp = self.linear_relu_stack(torch.tensor([x[i-1,j], x[i,j-1], x[i+1,j], x[i,j+1], x[i,j]], dtype=torch.float32))\n",
    "                b = self.globalparam['close_to_minus_1'](tmp)\n",
    "                ret[i-1, j-1] = self.linear_relu_stack2(b)\n",
    "        return ret\n",
    "\n",
    "\n",
    "\n",
    "# what the GenConv Function do is that it apply Kernel class in input just like Convolution.\n",
    "\n",
    "gg = {'kernel': Kernel(), 'a': 1, 'b': 10000, 'input': torch.zeros(28, 28, dtype=torch.float32), 'close_to_minus_1': CloseToMinus1()}\n",
    "\n",
    "\n",
    "class OrNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 1-nn.ReLU()(-x.sum()*100+1)\n",
    "        \n",
    "\n",
    "class SCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Initializer = Initializer()\n",
    "        self.ornet = OrNet()\n",
    "        self.globalparam = gg\n",
    "        self.extractnet = ExtractNet(self.globalparam)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.globalparam['input'] = x\n",
    "        tmp = self.Initializer(x)\n",
    "        for _ in range (40):\n",
    "            tmp = ConvLayer(self.globalparam)(tmp)\n",
    "        return self.ornet(self.extractnet(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADjElEQVR4nO3dMW7UUBRA0W+EIFJqmjRsIR0LoMiaKVhAOrZAQ0ONBDSfiorgZMgM4zs+p/WM8purN8qT7WXOOYDte3HuAwBPI1aIECtEiBUixAoRYoWIl4d8+NXyel6N61OdBXbv+/g2fs4fy0PXDor1alyPd8v745wK+MP9/PjXa34GQ4RYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiDjoxVRsz4cvn1av393c/pdzcHomK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIcIrH4/gua9dfOz7MIbJChlihQixQoRYIUKsECFWiBArRNizbpwdLb+ZrBAhVogQK0SIFSLEChFihQixQoQ9K6vW9riP7YA5LpMVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQsZtXPq69unDLf/uc52ZbTFaIECtEiBUixAoRYoUIsUKEWCFiN3vWNXc3t+c+wj+zh90PkxUixAoRYoUIsUKEWCFCrBAhVoiwZ71w9rCXw2SFCLFChFghQqwQIVaIECtEWN3Enfr2Pquf7TBZIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQjPDWaz1p5ZfOrnJW+RyQoRYoUIsUKEWCFCrBAhVojYzepmj//q57KYrBAhVogQK0SIFSLEChFihQixQsRu9qwc39otbByfyQoRYoUIsUKEWCFCrBAhVogQK0TYs7LKfcDbYbJChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSKWOefTP7wsX8cYn093HNi9t3PONw9dOChW4Hz8DIYIsUKEWCFCrBAhVogQK0SIFSLEChFihYhfsag9tgkjsqoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADgklEQVR4nO3dMW4TQRiA0V0UhUipaWhyBToOQMGZKTgAHVegoUkdCWiGAxAU29nV+LPfa9eyp/Cn3/JodtcxxgKcvzezFwAcRqwQIVaIECtEiBUixAoRN8e8+HZ9O+6W+73WAlfv1/K0/Bm/1+euHRXr3XK/fFw/bbMq4B/fxtf/XvMzGCLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsULEzewFwB6+/Pw+7bM/v/+wy/uarBAhVogQK0SIFSLEChFihQhbN1yl126vzNgaMlkhQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoWITZ/POuOZlXCKl76rr31+6x5MVogQK0SIFSLEChFihQixQsSmWzfn+Hf3Fop/83N5TFaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIWLT86zXauYtWJ2lPU3xjLLJChFihQixQoRYIUKsECFWiBArRNhn3cA57slxeUxWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEI3JMM/MWri85x7WZrBAhVogQK0SIFSLEChFihQixQoR9VqYp38J1xj6syQoRYoUIsUKEWCFCrBAhVogQK0TYZz1AeT+Qy2GyQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUiHJGDE8w4NmmyQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVItYxxuEvXtfHZVl+7LccuHoPY4x3z104KlZgHj+DIUKsECFWiBArRIgVIsQKEWKFCLFChFgh4i/9QzeHVhvewAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADmklEQVR4nO3dMW7UUBRAURtFECk1DQ1boGMBFKyZggXQsQUamtSREprPAghJZuDHvvE5rUfy10hXb6Qne9YxxgLs36utDwA8jVghQqwQIVaIECtEiBUiLk758Ov1zbhcrmadBQ7vdrlZfo279b5rJ8V6uVwtH9dP/+dUwB++ja9/veZnMESIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoWIi60PwHF9+fl9s3t/fvdhs3ufy2SFCLFChFghQqwQIVaIECtEWN2wW8X1ykwmK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBDhvcFxW/5t4pE99L3Pet+xyQoRYoUIsUKEWCFCrBAhVogQK0TYs75wM//j9LEd72P3tiM+jckKEWKFCLFChFghQqwQIVaIsLrhkIprI5MVIsQKEWKFCLFChFghQqwQIVaIsGeNm/kI3Ev2r9/bFntakxUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiPA8K2eb/Sxt8d2+M5msECFWiBArRIgVIsQKEWKFCLFChD3rzs3eNe75vcN7PtsWTFaIECtEiBUixAoRYoUIsUKE1c3OFf+akDlMVogQK0SIFSLEChFihQixQoRYIcKe9eD2vIfd89m2eHzPZIUIsUKEWCFCrBAhVogQK0SIFSLsWQ/O6z47TFaIECtEiBUixAoRYoUIsUKEWCHiWfese34+EfbOZIUIsUKEWCFCrBAhVogQK0Q86+rG41hwPpMVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQsY4xnv7hdb1eluXHvOPA4b0fY7y978JJsQLb8TMYIsQKEWKFCLFChFghQqwQIVaIECtEiBUifgMdTECNAkY0zAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADrUlEQVR4nO3cMW7TYBiAYRtVUKkzSxeu0I0DMPTMGTgAW67AkoUZCVjMAWgTh8aJ3+R5VkfRr0ivPiuf7HGapgFYv3eXPgAwj1ghQqwQIVaIECtEiBUi7o758Pvxw3Q/PCx1Frh5v4afw5/p9/jStaNivR8ehs/jl9OcCvjHt+nrq9fcBkOEWCFCrBAhVogQK0Qc9W8w57fZbfdef358Oss5uDyTFSLEChFihQixQoRYIUKsECFWiLBnneHQrvOt7EqZw2SFCLFChFghQqwQIVaIECtEWN2cwKHVy9KrH26DyQoRYoUIsUKEWCFCrBAhVogQK0TYs67AW/awa97hevTvtExWiBArRIgVIsQKEWKFCLFChFghwp51BewjmcNkhQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEeERuBo+wsQYmK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBDhvcErsNltL32E/+J9yudlskKEWCFCrBAhVogQK0SIFSLEChH2rCuw5n1ldQd8jUxWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQsTVvIq0/MrM6tmr5x6Gdb/+9TUmK0SIFSLEChFihQixQoRYIUKsEHE1e9Yl92aH9onFnV3Bvt/9Fn9zkxUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsEHE1j8hxfW7xMbh9TFaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFiLtLH+AabHbbxb77+fFpse+mxWSFCLFChFghQqwQIVaIECtEiBUi7FlnsOtkDUxWiBArRIgVIsQKEWKFCLFChFghYpymaf6Hx/HHMAzflzsO3LxP0zR9fOnCUbECl+M2GCLEChFihQixQoRYIUKsECFWiBArRIgVIv4C5JxBHgEaxsIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADk0lEQVR4nO3cMW4TURRA0RkUQaTUNDRsgY4FULBmChaQLlugoaFGAprPAhLbMczEvjPntOPiW9bVs/T0Zx5jTMD1e3XpAwDPI1aIECtEiBUixAoRYoWIm3M+/Hp+M26nu7XOArv3a/o5/Rm/56eenRXr7XQ3fZw/LXMq4JH78fXgM3+DIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIuLn0AV7Kl+8PB599fvfhxc4B/8pkhQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSJ2897gY469U3gJ3kvMEkxWiBArRIgVIsQKEWKFCLFChNXNZLVCg8kKEWKFCLFChFghQqwQIVaIECtEZPasa15jW/uK3Jq2vCM+9rts+XsfYrJChFghQqwQIVaIECtEiBUixAoRmT3rKVvdu5V3wCzLZIUIsUKEWCFCrBAhVogQK0SIFSI2s2c9Zav7yq1+Lx4zWSFCrBAhVogQK0SIFSLEChFihYjd7FmP2epdWLbFZIUIsUKEWCFCrBAhVogQK0RY3Uzta2bWTvthskKEWCFCrBAhVogQK0SIFSLEChGZPev/7hPX3Eee2tPahbIEkxUixAoRYoUIsUKEWCFCrBAhVojI7FnLyvdl9+oad+MmK0SIFSLEChFihQixQoRYIUKsEGHPuoBr3MmxPSYrRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsULEPMZ4/ofn+cc0Td/WOw7s3vsxxtunHpwVK3A5/gZDhFghQqwQIVaIECtEiBUixAoRYoUIsULEX826OxrcXF/sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "cycle_dataset = np.load('cycle_dataset.npz')\n",
    "train_images = cycle_dataset['train_images']\n",
    "train_labels = cycle_dataset['train_labels']\n",
    "test_images = cycle_dataset['test_images']\n",
    "test_labels = cycle_dataset['test_labels']\n",
    "def show(X):\n",
    "    '''\n",
    "    Changing inf to 40 can get a picture with more detail.\n",
    "    '''\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if X[i,j] > 1000:\n",
    "                X[i,j] = 40\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X)\n",
    "    plt.show()\n",
    "\n",
    "model = SCNN()\n",
    "for i in range(10,15):\n",
    "    demoinput = test_images[i]\n",
    "    show(test_images[i])\n",
    "    print(model(demoinput).item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b280a9d37a9bd438494aeea05dea499402c008750893dbc347293e426dd269af"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('web')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
